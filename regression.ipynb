{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Univariate Linear and Polynomial Regression\n",
    "\n",
    "In this notebook, we will try to solve the simple problem of univariate linear and polynomial regression using two approaches: closed form solution and optimization using gradient descent.\n",
    "\n",
    "First, we will generate 20 samples of 2-d data from a line and a polynomial in the form $\\mathcal{D}=\\{x_i, y_i\\}_{i=1}^N$, where $N=20$.\n",
    "We will visualize this data and will try to fit a line and a polynomial using the methods we learnt.\n",
    "\n",
    "We will fit a linear model using both the closed form solution: $\\theta^* = (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{y}$\n",
    "\n",
    "Finally, we will fit a polynomial using **gradient descent** as an optimization algorithm. For this, we will use **Pytorch** as the framework.\n",
    "\n",
    "In all cases, we will visualise the function learnt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Generation\n",
    "\n",
    "Let's try to create samples from the line: $y = 3x + 4$. We want to generate some samples but also we want to put in some noise into the mix.\n",
    "\n",
    "Write some code to generate 30 such samples in the following block. Let's create 2 pytorch 30 dimensional tensors: $X$ which contains 30 values for x and another $y$ which contains the corresponding $y$ values. Of course, make sure to make the data realistic (a.k.a noisy!!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.tensor(10 * torch.rand(30))\n",
    "\n",
    "## Write code below to create target outputs for x\n",
    "## CODE BELOW =======\n",
    "\n",
    "## ==================\n",
    "\n",
    "x_linear = x\n",
    "y_linear = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to plot the data and visualise it.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "\n",
    "sb.set_style('whitegrid')\n",
    "\n",
    "plt.plot(x_linear.numpy(), y_linear.numpy(), linestyle=\"\", marker='o')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try the same process to create samples from a polynomial: $y = 4x^3 - 2x^2 - 6x + 5$. Instead of getting samples between 0 and 10, let's try getting these samples between 0 and 100.\n",
    "\n",
    "Write code below to create 50 samples from this polynomial (don't forget to add in some noise to make the samples realistic).\n",
    "\n",
    "Follow the code above to also plot the samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write code below to generate the tensors X and Y following specifications mentioned above.\n",
    "## CODE BELOW =======\n",
    "\n",
    "## ==================\n",
    "\n",
    "x_poly = x\n",
    "y_poly = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write code below to plot the data and visualise it.\n",
    "## CODE BELOW =======\n",
    "\n",
    "\n",
    "## =================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model\n",
    "\n",
    "Next, we want to define the model for fitting the above datasets.\n",
    "\n",
    "First, let's try to see if we can fit the optimal model using the closed form solution for linear regression on the dataset $x_{linear}, y_{linear}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CODE BELOW =================\n",
    "# Don't forget augmenting the matrix of x before applying the closed form solution.\n",
    "# Consider looking up torch functions for matrix operations.\n",
    "# Also look up concatenation operations for pytorch tensors.\n",
    "\n",
    "# Step 1: Augment the matrix x_linear below.\n",
    "# Sanity check: The shape of the augmented matrix should be [30, 2].\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Compute the term (X^TX)^-1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Compute the term X^Ty\n",
    "# You might need to change the shape of the vector y. Consider looking up torch.unsqueeze\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Compute the optimal parameters using the closed form solution.\n",
    "# The optimal parameters should have shape [2, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report the values of the optimal parameter vector.\n",
    "# Are these values close to the parameters of the line we used to create the data?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's visualise the line we just fit!\n",
    "# Plot the line along with the data points that you plotted before.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yaay!! You just successfully fit a line!! Congratulations!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent\n",
    "\n",
    "Now that we have explored the closed form solution method of fitting a line on the given data, let's try the more general optimization algorithm: Gradient Descent.\n",
    "\n",
    "We already have the data. Let's spend some time focusing on the different steps here. It'll be very useful in future as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 1: Define the model\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "class LinearModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearModel, self).__init__()\n",
    "        self.theta_0 = nn.Parameter(torch.tensor([1.]))\n",
    "        self.theta_1 = nn.Parameter(torch.tensor([1.]))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        x can be a minibatch of scalars.\n",
    "        '''\n",
    "        return (self.theta_0 + self.theta_1 * x)\n",
    "\n",
    "linear_model = LinearModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Define the loss function\n",
    "\n",
    "class SquareLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SquareLoss, self).__init__()\n",
    "    \n",
    "    def forward(self, inp, target):\n",
    "        d = (inp - target) ** 2\n",
    "        return torch.mean(d)\n",
    "\n",
    "squared_loss = SquareLoss()\n",
    "\n",
    "# Note: You can get squared loss (and a lot of other conventional loss functions) as a predefined loss in pytorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Define the optimizer: SGD (Stochastic Gradient Descent)\n",
    "\n",
    "optimizer = torch.optim.SGD(linear_model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Defining the training function\n",
    "\n",
    "def train(model, x, y, optimizer, loss_fn):\n",
    "    n_epochs = 1000\n",
    "    theta_0s = []\n",
    "    theta_1s = []\n",
    "    losses = []\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        op = model(x)\n",
    "        loss = loss_fn(op, y)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        theta_0s.append(model.theta_0.item())\n",
    "        theta_1s.append(model.theta_1.item())\n",
    "        losses.append(loss.item())\n",
    "        print (f'==> Epoch {epoch+1}, loss: {loss.item()}, theta_0: {model.theta_0.item()}, theta_1: {model.theta_1.item()}')\n",
    "        \n",
    "    return theta_0s, theta_1s, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Training the model\n",
    "\n",
    "theta_0s, theta_1s, losses = train(linear_model, x_linear, y_linear, optimizer, squared_loss)\n",
    "\n",
    "# Do the parameters theta_0 and theta_1 look like the ones we used for generating the data at the end of training?\n",
    "# What happens when we play around with the learning rate for the optimizer? What if we set it to 0.001? What if we set it to 0.1?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Visualise the line we just learnt.\n",
    "\n",
    "sb.set_style('whitegrid')\n",
    "\n",
    "plt.plot(x_linear.numpy(), y_linear.numpy(), linestyle=\"\", marker='o')\n",
    "plt.plot(x_linear.numpy(), linear_model(x_linear).detach().numpy(), color='r')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you apply and reuse the above code to perform polynomial regression on the generated non-linear toy dataset? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CODE BELOW ============================================\n",
    "# Note: You might need to try out torch.Adam here instead of torch.SGD. Look them up!\n",
    "# Note2: Careful when you plot the output of the polynomial, you might need to sort the x's, it's not a line.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = train(polynomial_model, x_poly, y_poly, polynomial_optimizer, squared_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.set_style('whitegrid')\n",
    "\n",
    "plt.plot(x_poly.numpy(), y_poly.numpy(), linestyle=\"\", marker='o')\n",
    "x_poly_sort, _ = torch.sort(x_poly)\n",
    "plt.plot(x_poly_sort.numpy(), polynomial_model(x_poly_sort).detach().numpy(), linewidth=2, color='r')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have solved the regression problem on toy settings, try branching out and applying your skills on real-world regression datasets!\n",
    "\n",
    "Look up a few tutorials on this available online and try to replicate their solutions (or make your own!).\n",
    "Here's one I found nice: https://towardsdatascience.com/polynomial-regression-using-pytorch-from-scratch-500b7887b0ed. Feel free to follow your own.\n",
    "\n",
    "Here, you'll find a bunch of regression (and other) datasets: https://archive.ics.uci.edu/ml/datasets.php?format=&task=reg&att=&area=&numAtt=&numIns=&type=&sort=nameUp&view=table\n",
    "\n",
    "Homework for next week is to finish up this notebook and also optionally do a polynomial multivariate regression task on a separate dataset above.\n",
    "\n",
    "Also, next week, we should chat about the **train, validation and test splits**.\n",
    "\n",
    "Enjoy!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
